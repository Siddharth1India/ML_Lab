{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCPVvjqbnj9H"
      },
      "source": [
        "**Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "4gjDBklCnJB2"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import *\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xV_D3GvSnqE2"
      },
      "source": [
        "**Load the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "RIBmJYuXnsa2"
      },
      "outputs": [],
      "source": [
        "data = load_breast_cancer() #refer: http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer\n",
        "\n",
        "# data with features\n",
        "X = data.data\n",
        "\n",
        "# data class labels\n",
        "y = data.target\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean radius  mean texture  ...  worst fractal dimension  target\n",
              "0        17.99         10.38  ...                  0.11890     0.0\n",
              "1        20.57         17.77  ...                  0.08902     0.0\n",
              "2        19.69         21.25  ...                  0.08758     0.0\n",
              "3        11.42         20.38  ...                  0.17300     0.0\n",
              "4        20.29         14.34  ...                  0.07678     0.0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "con = np.c_[X, y]\n",
        "columns = np.append(data.feature_names, ['target'])\n",
        "df = pd.DataFrame(con, columns = columns)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmIAUYfusNJK"
      },
      "source": [
        "**Print the number of data points, number of features and number of classes in the given data set.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Ib_fr2lDsaQa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of Instances: 569\n",
            "Number of Features: 30\n",
            "Number of Classes: 2\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of Instances: {len(df)}\")\n",
        "print(f\"Number of Features: {len(df.columns)-1}\")\n",
        "print(f\"Number of Classes: {len(df['target'].unique())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FSg49Uxsnw6"
      },
      "source": [
        "**Splitting data into Train and test sets with Stratified Sampling using train_test_split()**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "XyGtQkgGsqQa"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((455, 30), (114, 30), (455,), (114,))"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZEUDkrmsr1S"
      },
      "source": [
        "**Data Preprocessing using column standardisation. Use sklearn.preprocessing.StandardScaler().**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "W3IqnsLtsxdJ"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.440753</td>\n",
              "      <td>-0.435319</td>\n",
              "      <td>-1.362085</td>\n",
              "      <td>-1.139118</td>\n",
              "      <td>0.780573</td>\n",
              "      <td>0.718921</td>\n",
              "      <td>2.823135</td>\n",
              "      <td>-0.119150</td>\n",
              "      <td>1.092662</td>\n",
              "      <td>2.458173</td>\n",
              "      <td>-0.263800</td>\n",
              "      <td>-0.016052</td>\n",
              "      <td>-0.470414</td>\n",
              "      <td>-0.474761</td>\n",
              "      <td>0.838365</td>\n",
              "      <td>3.251027</td>\n",
              "      <td>8.438937</td>\n",
              "      <td>3.391987</td>\n",
              "      <td>2.621166</td>\n",
              "      <td>2.061208</td>\n",
              "      <td>-1.232861</td>\n",
              "      <td>-0.476309</td>\n",
              "      <td>-1.247920</td>\n",
              "      <td>-0.973968</td>\n",
              "      <td>0.722894</td>\n",
              "      <td>1.186732</td>\n",
              "      <td>4.672828</td>\n",
              "      <td>0.932012</td>\n",
              "      <td>2.097242</td>\n",
              "      <td>1.886450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.974096</td>\n",
              "      <td>1.733026</td>\n",
              "      <td>2.091672</td>\n",
              "      <td>1.851973</td>\n",
              "      <td>1.319843</td>\n",
              "      <td>3.426275</td>\n",
              "      <td>2.013112</td>\n",
              "      <td>2.665032</td>\n",
              "      <td>2.127004</td>\n",
              "      <td>1.558396</td>\n",
              "      <td>0.805319</td>\n",
              "      <td>-0.812687</td>\n",
              "      <td>0.751957</td>\n",
              "      <td>0.877170</td>\n",
              "      <td>-0.896053</td>\n",
              "      <td>1.181222</td>\n",
              "      <td>0.183628</td>\n",
              "      <td>0.600596</td>\n",
              "      <td>-0.317717</td>\n",
              "      <td>0.529636</td>\n",
              "      <td>2.173314</td>\n",
              "      <td>1.311279</td>\n",
              "      <td>2.081617</td>\n",
              "      <td>2.137405</td>\n",
              "      <td>0.761928</td>\n",
              "      <td>3.265601</td>\n",
              "      <td>1.928621</td>\n",
              "      <td>2.698947</td>\n",
              "      <td>1.891161</td>\n",
              "      <td>2.497838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.399982</td>\n",
              "      <td>-1.249622</td>\n",
              "      <td>-1.345209</td>\n",
              "      <td>-1.109785</td>\n",
              "      <td>-1.332645</td>\n",
              "      <td>-0.307355</td>\n",
              "      <td>-0.365558</td>\n",
              "      <td>-0.696502</td>\n",
              "      <td>1.930333</td>\n",
              "      <td>0.954379</td>\n",
              "      <td>0.027521</td>\n",
              "      <td>1.963060</td>\n",
              "      <td>-0.120958</td>\n",
              "      <td>-0.350779</td>\n",
              "      <td>0.572766</td>\n",
              "      <td>0.739499</td>\n",
              "      <td>0.320656</td>\n",
              "      <td>0.589462</td>\n",
              "      <td>2.615041</td>\n",
              "      <td>0.718928</td>\n",
              "      <td>-1.295284</td>\n",
              "      <td>-1.040811</td>\n",
              "      <td>-1.245220</td>\n",
              "      <td>-0.999715</td>\n",
              "      <td>-1.438693</td>\n",
              "      <td>-0.548564</td>\n",
              "      <td>-0.644911</td>\n",
              "      <td>-0.970239</td>\n",
              "      <td>0.597602</td>\n",
              "      <td>0.057894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.981797</td>\n",
              "      <td>1.416222</td>\n",
              "      <td>-0.982587</td>\n",
              "      <td>-0.866944</td>\n",
              "      <td>0.059390</td>\n",
              "      <td>-0.596788</td>\n",
              "      <td>-0.820203</td>\n",
              "      <td>-0.845115</td>\n",
              "      <td>0.313264</td>\n",
              "      <td>0.074041</td>\n",
              "      <td>-0.538505</td>\n",
              "      <td>0.536473</td>\n",
              "      <td>-0.657950</td>\n",
              "      <td>-0.496590</td>\n",
              "      <td>0.065475</td>\n",
              "      <td>-0.822404</td>\n",
              "      <td>-0.685565</td>\n",
              "      <td>-0.898485</td>\n",
              "      <td>0.123299</td>\n",
              "      <td>-0.431547</td>\n",
              "      <td>-0.829197</td>\n",
              "      <td>1.593530</td>\n",
              "      <td>-0.873572</td>\n",
              "      <td>-0.742947</td>\n",
              "      <td>0.796624</td>\n",
              "      <td>-0.729392</td>\n",
              "      <td>-0.774950</td>\n",
              "      <td>-0.809483</td>\n",
              "      <td>0.798928</td>\n",
              "      <td>-0.134497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.117700</td>\n",
              "      <td>-1.010259</td>\n",
              "      <td>-1.125002</td>\n",
              "      <td>-0.965942</td>\n",
              "      <td>1.269511</td>\n",
              "      <td>-0.439002</td>\n",
              "      <td>-0.983341</td>\n",
              "      <td>-0.930600</td>\n",
              "      <td>3.394436</td>\n",
              "      <td>0.950213</td>\n",
              "      <td>0.402278</td>\n",
              "      <td>0.440382</td>\n",
              "      <td>0.219314</td>\n",
              "      <td>-0.115532</td>\n",
              "      <td>0.171911</td>\n",
              "      <td>-0.787970</td>\n",
              "      <td>-0.783509</td>\n",
              "      <td>-0.588648</td>\n",
              "      <td>2.604015</td>\n",
              "      <td>0.765981</td>\n",
              "      <td>-1.085129</td>\n",
              "      <td>-1.334616</td>\n",
              "      <td>-1.117138</td>\n",
              "      <td>-0.896549</td>\n",
              "      <td>-0.174876</td>\n",
              "      <td>-0.995079</td>\n",
              "      <td>-1.209146</td>\n",
              "      <td>-1.354582</td>\n",
              "      <td>1.033544</td>\n",
              "      <td>-0.205732</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         0         1         2   ...        27        28        29\n",
              "0 -1.440753 -0.435319 -1.362085  ...  0.932012  2.097242  1.886450\n",
              "1  1.974096  1.733026  2.091672  ...  2.698947  1.891161  2.497838\n",
              "2 -1.399982 -1.249622 -1.345209  ... -0.970239  0.597602  0.057894\n",
              "3 -0.981797  1.416222 -0.982587  ... -0.809483  0.798928 -0.134497\n",
              "4 -1.117700 -1.010259 -1.125002  ... -1.354582  1.033544 -0.205732\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "trans = StandardScaler()\n",
        "X_train = trans.fit_transform(X_train)\n",
        "X_train = pd.DataFrame(X_train)\n",
        "X_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hI7Xizrsx9y"
      },
      "source": [
        "## **Implement Logistic Regression Using Gradient Descent: without using sklearn.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynujCs0lwy4n"
      },
      "source": [
        "\n",
        "In this algorithm, $n$ is the total number of datapoints in dataset. \n",
        "$\\alpha$ is the learning rate to be used in gradient descent. For this work, just fix $\\alpha = 0.001$.\n",
        "\n",
        "The predicted value for data point $x$ is $y_{pred} = σ(w^{T}x + b)$, where $σ$ is a sigmoid function.\n",
        "\n",
        "**ALGORITHM:**\n",
        "\n",
        "<br>\n",
        "\n",
        "* Initialize the weight_vector and intercept term to zeros (Write your code in <font color='blue'>def initialize_weights()</font>)\n",
        "\n",
        "* Create a loss function (Write your code in <font color='blue'>def logloss()</font>) \n",
        "\n",
        " $log loss = -1*\\frac{1}{n}\\Sigma_{for each y_{true},y_{pred}}(y_{true}log(y_{pred})+(1-y_{true})log(1-y_{pred}))$\n",
        "- for each epoch:\n",
        "\n",
        "    - for each data point say $x_{i}$ in train:\n",
        "\n",
        "        - calculate the gradient of loss function w.r.t each weight in weight vector (write your code in <font color='blue'>def gradient_dw()</font>)\n",
        "\n",
        "        $dw^{(t)} = \\frac{1}{n}(x_i(σ((w^{(t)})^{T} x_i+b^{t}) - y_i))$ <br>\n",
        "\n",
        "        - Calculate the gradient of the intercept (write your code in <font color='blue'> def gradient_db()</font>)\n",
        "\n",
        "           $ db^{(t)} = \\frac{1}{n}(σ((w^{(t)})^{T} x_i+b^{t}) - y_i))$\n",
        "\n",
        "        - Update weights and intercept usign gradient descent  <br>\n",
        "        $w^{(t+1)}← w^{(t)} - α(dw^{(t)}) $<br>\n",
        "\n",
        "        $b^{(t+1)}←b^{(t)} - α(db^{(t)}) $\n",
        "    - predict the output for all test data points with updated weights. (write your function in def prediction())\n",
        "    - calculate the log loss for train and test data points separately with the updated weights. Store these losses in the lists, train_loss and test_loss.\n",
        "    - And if you wish, you can compare the previous train loss and the current train loss, if it is not updating, then\n",
        "        you can stop the training\n",
        "    -return the updated weights, training and test loss lists.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "18XrII86wxbn"
      },
      "outputs": [],
      "source": [
        "def initialize_weights():\n",
        "    #initialize the weights as 1d array consisting of all zeros similar to the dimensions of input vector.\n",
        "    #initialize bias to zero\n",
        "    return np.zeros((1, 30))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "LvxGkvA-0bW6"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "def sigmoid(z):\n",
        "    ''' In this function, we will return sigmoid of z'''\n",
        "    # compute sigmoid(z) and return\n",
        "    return (1/(1+math.exp(-z)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "85VJ1n5Q0ig6"
      },
      "outputs": [],
      "source": [
        "def logloss(y_true, y_pred):\n",
        "    # you have been given two arrays y_true and y_pred and you have to calculate the logloss\n",
        "    return -((y_true*math.log(y_pred)) + (1-y_true)*math.log(1-y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1sFxfpm0yhA"
      },
      "outputs": [],
      "source": [
        "# w should be a vector of size as input data point. Size of w and dw be same.\n",
        "def gradient_dw(x, y, w, b, alpha, n):\n",
        "  # In this function, we will compute the gradient w.r.to w\n",
        "  pass    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWxvXtMI1KMr"
      },
      "outputs": [],
      "source": [
        "#b should be a scalar value\n",
        "def gradient_db(x,y,w,b):\n",
        "  # In this function, we will compute gradient w.r.to b \n",
        "  pass "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKttny689cmV"
      },
      "source": [
        "**For the prediction, if activation_value > 0.5 then assign label = 1 else label = 0**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGLAVthp5Ug_"
      },
      "outputs": [],
      "source": [
        "def predict():\n",
        "  # predicting the class label for a data point.\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yu1wK8Xq1mTI"
      },
      "outputs": [],
      "source": [
        "def logistic_regression():\n",
        "  # implement your algorithm\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYe3WqKO5kW1"
      },
      "source": [
        "**Plot your train and test loss vs epochs. Plot epoch number on X-axis and loss on Y-axis and make sure that the curve is converging**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdvYIvpMtRra"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4Wnv-xA7j6c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UEbsJqt7vJs"
      },
      "source": [
        "**Compute the final accuracy on test dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhCDgO508XAZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUcuGi8Q-HE7"
      },
      "source": [
        "**BONUS: Train your model with varying values of learning rates say ranging in $[0.1, 0.01, 0.001, 0.0001]$ and plot the performances.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCawXEH_8XbZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEGCMsMY-s8a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.1 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "93c3a718b4c6642ce4c45cce76395d725a388a32f575fa81b43fa67ce89bca37"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
